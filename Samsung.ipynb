{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Anna Beatriz Lima\n",
    "\n",
    "Nome: Pedro Rubens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Importando Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\AnnaBeatriz\\INSPER\\2020.1\\cdados\\Projeto1-ttw\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun√ß√£o para limpar as bases \n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    import string\n",
    "    tira_mencoes = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    tira_links = re.sub(r'http\\S+', '', tira_mencoes)\n",
    "    punctuation = '[!-.:?;@\\/]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', tira_links)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_data = pd.read_excel('samsung1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Escolhemos a samsung que consiste em uma marca de celulares, rel√≥gios e outros produtos voltados a tecnologia. Classificamos como relevante todos aqueles tweets que exibem alguma cr√≠tica ou sugest√£o. Coisas que s√£o relevantes para a marca em si e sobre os produtos que a mesma oferece e classificamos como irrelevantes todos os tweets que cont√©m informa√ß√µes superficiais e que n√£o agregam nada para a marca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### limpeza das bases e classifica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifica√ß√£o\n",
    "sum_negativo = samsung_data['relevancia'] == 2.0\n",
    "negativo = samsung_data.loc[sum_negativo, :]\n",
    "\n",
    "sum_positivo = samsung_data['relevancia'] == 1.0\n",
    "positivo = samsung_data.loc[sum_positivo, :]\n",
    "\n",
    "sum_neutro = samsung_data['relevancia'] == 0.0\n",
    "neutro = samsung_data.loc[sum_neutro, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivo_text = ''\n",
    "for t in positivo['Treinamento']:\n",
    "    t = str(t)\n",
    "    positivo_text += t\n",
    "    \n",
    "samsung_pos = cleanup(positivo_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativo_text = ''\n",
    "for t in negativo['Treinamento']:\n",
    "    t = str(t)\n",
    "    negativo_text += t\n",
    "    \n",
    "samsung_neg = cleanup(negativo_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutro_text = ''\n",
    "for t in neutro['Treinamento']:\n",
    "    t = str(t)\n",
    "    neutro_text += t\n",
    "    \n",
    "samsung_neu = cleanup(neutro_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059343434343434344"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensinando o classificador para positivo\n",
    "serie_samsung_pos = pd.Series(samsung_pos.split())\n",
    "tabela_samsung_pos = serie_samsung_pos.value_counts()\n",
    "tabela_samsung_pos_relativa = serie_samsung_pos.value_counts(True)\n",
    "tabela_samsung_pos_relativa.sum()\n",
    "tabela_samsung_pos_relativa[\"samsung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047619047619047616"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensinando o classificador para negativo\n",
    "serie_samsung_neg = pd.Series(samsung_neg.split())\n",
    "tabela_samsung_neg = serie_samsung_neg.value_counts()\n",
    "tabela_samsung_neg_relativa = serie_samsung_neg.value_counts(True)\n",
    "tabela_samsung_neg_relativa.sum()\n",
    "tabela_samsung_neg_relativa[\"samsung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044142614601018676"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensinando o classificador para neutro\n",
    "serie_samsung_neu = pd.Series(samsung_neu.split())\n",
    "tabela_samsung_neu = serie_samsung_neu.value_counts()\n",
    "tabela_samsung_neu_relativa = serie_samsung_neu.value_counts(True)\n",
    "tabela_samsung_neu_relativa.sum()\n",
    "tabela_samsung_neu_relativa[\"samsung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilidade de conter samsung\n",
    "samsung = samsung_pos + samsung_neg + samsung_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047082348663879295"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construindo uma tabela samsung\n",
    "serie_samsung = pd.Series(samsung.split())\n",
    "tabela_samsung_relativa = serie_samsung.value_counts(True)\n",
    "tabela_samsung_relativa[\"samsung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interse√ßao de condi√ß√µes\n",
    "set_posi = set(tabela_samsung_pos_relativa.index)\n",
    "set_nega = set(tabela_samsung_neg_relativa.index)\n",
    "set_neut = set(tabela_samsung_neu_relativa.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando para um tweet\n",
    "\n",
    "frase = 'samsung me mandou um convite bacana para a pr√© venda do galaxy s20, aceitei...mas e a√≠ cad√™ o dinheiro kkkkk sem falar do absurdo de caro que deve ser aqui no brasil'\n",
    "frase = cleanup(frase.lower())\n",
    "\n",
    "tabela_frase = pd.Series(frase.split())\n",
    "tabela_frase_a = tabela_frase.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samsung' 'me' 'mandou' 'um' 'convite' 'bacana' 'para' 'a' 'pr√©' 'venda'\n",
      " 'do' 'galaxy' 's20' 'aceitei' 'mas' 'e' 'a√≠' 'cad√™' 'o' 'dinheiro'\n",
      " 'kkkkk' 'sem' 'falar' 'do' 'absurdo' 'de' 'caro' 'que' 'deve' 'ser'\n",
      " 'aqui' 'no' 'brasil']\n",
      "1.2916203455484921e-42\n",
      "1.4305544817694005e-83\n",
      "9.219763761821485e-66\n",
      "1.859595189373579e-43\n",
      "3.0582295411030993e-84\n",
      "5.92304038070844e-66\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades\n",
    "#pneg = tabela_samsung_relativa[serie_samsung_neg]\n",
    "#probneg = len(tabela_samsung)/len(serie_samsung_neg)\n",
    "\n",
    "tabela_samsung_absolut = serie_samsung.value_counts()\n",
    "tabela_samsung_absolut.sum()\n",
    "\n",
    "ppos = tabela_samsung_pos.sum()/tabela_samsung_absolut.sum()\n",
    "pneg = tabela_samsung_neg.sum()/tabela_samsung_absolut.sum()\n",
    "pneu = tabela_samsung_neu.sum()/tabela_samsung_absolut.sum()\n",
    "\n",
    "\n",
    "print(tabela_frase.values)\n",
    "\n",
    "pposPO=tabela_samsung_pos_relativa[tabela_frase.values]\n",
    "print(pposPO.prod())\n",
    "\n",
    "pposNG=tabela_samsung_neg_relativa[tabela_frase.values]\n",
    "print(pposNG.prod())\n",
    "\n",
    "pposNT=tabela_samsung_neu_relativa[tabela_frase.values]\n",
    "print(pposNT.prod())\n",
    "\n",
    "\n",
    "pposf =pposPO.prod()*ppos\n",
    "print(pposf)\n",
    "pnegf =pposNG.prod()*pneg\n",
    "print(pnegf)\n",
    "pneuf =pposNT.prod()*pneu\n",
    "print(pneuf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo a base teste\n",
    "base_teste = pd.ExcelFile('samsung1.xlsx')\n",
    "df1 = pd.read_excel(base_teste,'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.307703531150129e-26 4.610259100337782e-28 1.687693559375596e-29\n",
      "                                                 Teste  relevancia  classif\n",
      "0    t√¢nia rocha um pouquinho de tudo - free fire n...           0      2.0\n",
      "1    cupom notebook e computadores -inform√°tica ace...           0      2.0\n",
      "2    @samsungbrasil verdade ü•∫üò•, j√° pedi um galaxy w...           1      2.0\n",
      "3    rt @purplesidestore: üíòpromo√ß√£o - cases bts (ip...           0      1.0\n",
      "4    @samsungbrasil eh s√©rio samsung t√¥ sem tv h√° 3...           0      2.0\n",
      "5    @phantomrenegado depois que parar de funcionar...           2      1.0\n",
      "6    @asusbr bd! comprei um aparelho dia 03/03, hj ...           2      1.0\n",
      "7    a samsung perguntando se eu quero saber tudo s...           0      1.0\n",
      "8    @andreiamelody1 amg n beije os vendedores da s...           0      0.0\n",
      "9    @samsungbrasil @lucassi28687778 kkkk samsung t...           2      1.0\n",
      "10   a samsung t√° de sacanagem que vai lan√ßar o gal...           0      1.0\n",
      "11   rapaziada\\n\\nt√¥ vendendo um monitor de 21,5' p...           0      2.0\n",
      "12   @wagner_porto @xiaomibrasil meu t√° morto desde...           1      2.0\n",
      "13   nosso cso, tom√°s trojan, tamb√©m √© um dos indic...           0      1.0\n",
      "14   @brunosader bruno, que tal participar da minha...           0      2.0\n",
      "15     samsung at√© o meu sono ela atrapalha me ligando           2      1.0\n",
      "16          @hobipied samsung. eles s√£o patrocinadora.           0      0.0\n",
      "17   rt @trem_bebele: @vulgoloma eu nem ia posta ,t...           0      1.0\n",
      "18   samsung pay e google pay agora aceitam fun√ß√£o ...           1      1.0\n",
      "19   mds sabe so queria meu cll de volta eu desapre...           0      2.0\n",
      "20   fabricantes de smartphones deveriam realocar o...           2      2.0\n",
      "21   algu√©m me traz um ciga e um carregador de sams...           0      1.0\n",
      "22   comprei um celular novinho da @samsung e ja es...           2      0.0\n",
      "23   eu c o samsung carregava o tele tipo d 2 em 2 ...           1      2.0\n",
      "24   @faabisf samsung, pq motorola depois de uns 6 ...           1      2.0\n",
      "25   samsung me explica pra mim, pq eu dei 4 mil re...           0      1.0\n",
      "26   rt @gustavo65251461: c√¢mera de iphone // c√¢mer...           0      1.0\n",
      "27   indo pra mais um treinamento! \\nque eu volte c...           0      1.0\n",
      "28   ontem eu thalyta e sthe no shopping kkkk tiran...           0      2.0\n",
      "29   @googlenest smartview da samsung, que transmit...           2      1.0\n",
      "..                                                 ...         ...      ...\n",
      "210  rt @bts_br: üé• j-hope para a campanha do @bts_t...           0      1.0\n",
      "211  certeza q o yoongs tiro essa foto ae com um sa...           0      2.0\n",
      "212  @leticiaar_m kkkkkkk nao vou nem defender a sa...           1      1.0\n",
      "213  rt @surtadazex: o meu samsung √© igual mas por ...           0      1.0\n",
      "214  @bchartsnet vai flopar muito bc\\ntaylor: 6 #1 ...           0      2.0\n",
      "215  a huawei sem um pingo de vergonha na cara e co...           0      0.0\n",
      "216  @choegf @bts_twt a foto de samsung vei morro k...           0      0.0\n",
      "217  j√° baixei tanto jogo que na hora que eu ligo m...           0      1.0\n",
      "218  rt @canaltech: samsung anuncia primeiro lote d...           0      1.0\n",
      "219  rt @bts_br: üé• suga para a campanha do @bts_twt...           0      1.0\n",
      "220  üé• j-hope para a campanha do @bts_twt com a sam...           0      1.0\n",
      "221  rt @fbrazilianarmy: üé•| bts x samsung \\n\\n‚Äú#v n...           0      1.0\n",
      "222  rt @oficinadanet: samsung galaxy note 10+: vej...           0      2.0\n",
      "223  rt @bts_br: üé• rm para a campanha do @bts_twt c...           0      1.0\n",
      "224  üé• jimin para a campanha do @bts_twt com a sams...           0      1.0\n",
      "225  rt @yosoycaio: um iphone faz a mesma liga√ß√£o q...           0      2.0\n",
      "226  üé•| bts x samsung \\n\\n‚Äú#jungkook n√≥s mostra com...           0      1.0\n",
      "227  ele some e quando aparece √© cm uma foto tirada...           0      2.0\n",
      "228  rt @passionjeon: se √© para ficar perto do que ...           0      1.0\n",
      "229  üé•| bts x samsung \\n\\n‚Äú#rm n√≥s mostra como pode...           0      1.0\n",
      "230  n√© por nada n√£o mas n√£o sei como o povo defend...           0      1.0\n",
      "231  at√© agr sem acreditar que acharam o samsung po...           0      2.0\n",
      "232  rt @tourprojetosbts: [trad]\\n\"experimente aut√™...           0      2.0\n",
      "233  a samsung n√£o t√° errando üíú @bts_twt https://t....           0      2.0\n",
      "234  samsung lan√ßa novo celular e agora toda hora a...           1      1.0\n",
      "235                @augustobt use o samsung branquinho           0      2.0\n",
      "236  rt @chuufuku: o iphone era a boca de fog√£o a g...           0      1.0\n",
      "237  lan√ßamento do huawei p40 rolando na china. por...           2      2.0\n",
      "238  rt @bts_br: üé• v para a campanha do @bts_twt co...           0      1.0\n",
      "239  samsung minha filha vc atualiza a porra do cel...           2      1.0\n",
      "\n",
      "[240 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Percorrendo linha a linha e calculando probabilidades\n",
    "i=0\n",
    "for e in df1.Teste: \n",
    "    e = cleanup(e.lower())\n",
    "    x = re.sub(\"@[A-Za-z0-9]+\",\"\",e)\n",
    "    tweets = pd.Series(x.split())\n",
    "    \n",
    "    posit = 1\n",
    "    for p in tweets:\n",
    "        posit *= tabela_samsung_pos_relativa.get(p, 1)\n",
    "\n",
    "    negat = 1    \n",
    "    for p in tweets:\n",
    "        negat *= tabela_samsung_neg_relativa.get(p, 1)\n",
    "    \n",
    "    neutr = 1\n",
    "    for p in tweets:\n",
    "        neutr *= tabela_samsung_neu_relativa.get(p, 1)\n",
    "  \n",
    "    \n",
    "    posit = ppos*posit\n",
    "    negat = pneg*negat\n",
    "    neutr = pneu*neutr\n",
    "    \n",
    "    if posit > negat and posit > neutr:\n",
    "        classif = 1\n",
    "    elif negat > posit and negat > neutr:\n",
    "        classif = 2\n",
    "    elif neutr > posit and neutr > negat:\n",
    "        classif = 0\n",
    "        \n",
    "  \n",
    "    df1.loc[i, \"classif\"] = classif\n",
    "    i+=1\n",
    "    \n",
    "print(posit, negat,neutr)\n",
    "\n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classif</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classif     0.0  1.0  2.0\n",
       "relevancia               \n",
       "0             7  106   75\n",
       "1             2   11   13\n",
       "2             4   18    4"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compara√ß√£o entre Classifica√ß√£o Manual e o uso do classificador\n",
    "comparacao = (pd.crosstab(df1['relevancia'], df1['classif']))\n",
    "comparacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09166666666666666"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C√°lculo da porcentagem de acerto do Classificador\n",
    "j = 0\n",
    "total = 0\n",
    "while j < 240:\n",
    "    if df1.relevancia[j] == df1.classif[j]:\n",
    "        total += 1\n",
    "        \n",
    "    j+=1 \n",
    "total\n",
    "\n",
    "porc_acerto = total/len(df1)\n",
    "porc_acerto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Conclus√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos encontrar nesse trabalho a opini√£o publica sobre a marca de celulares Samsung, para isso pegamos uma serie de tweets relacionados a marca.\n",
    "Com a conclus√£o desse projeto, temos como resultado uma porcentagem bem abaixo do que era esperando. Com uma porcentagem de acerto por volta de 10% vimos que a grande maioria dos erros est√° nos tweets que nos colocamos o grau de relev√¢ncia como ‚ÄúNeutro‚Äù.\n",
    "    Como uma justificativa disso, podemos observar que o classificador possui uma margem de erro muito grande quando comparado a novos m√©todos voltados a ci√™ncia dos dados.\n",
    "    De modo a minimizar esse erro uma alternativa serie utilizar uma base maior de tweets para treinar nosso classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Outras aplica√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras aplica√ß√µes do  m√©todo de classifica√ß√£o de Naive Bayes podem ser encontradas por exemplo na an√°lise de dados de exames laboratoriais, e tamb√©m em caixa de entrada de emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
