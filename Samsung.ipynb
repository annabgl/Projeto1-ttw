{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Anna Beatriz Lima\n",
    "\n",
    "Nome: Pedro Rubens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Importando Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\AnnaBeatriz\\INSPER\\2020.1\\cdados\\Projeto1-ttw\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para limpar as bases \n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    tira_mencoes = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    tira_links = re.sub(r'http\\S+', '', tira_mencoes)\n",
    "    punctuation = '[!-.:?;@\\/]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', tira_links)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_data = pd.read_excel('samsung1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Escolhemos a samsung que consiste em uma marca de celulares, relógios e outros produtos voltados a tecnologia. Classificamos como relevante todos aqueles tweets que exibem alguma crítica ou sugestão. Coisas que são relevantes para a marca em si e sobre os produtos que a mesma oferece e classificamos como irrelevantes todos os tweets que contém informações superficiais e que não agregam nada para a marca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### limpeza das bases e classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificação\n",
    "sum_negativo = samsung_data['relevancia'] == 2.0\n",
    "negativo = samsung_data.loc[sum_negativo, :]\n",
    "\n",
    "sum_positivo = samsung_data['relevancia'] == 1.0\n",
    "positivo = samsung_data.loc[sum_positivo, :]\n",
    "\n",
    "sum_neutro = samsung_data['relevancia'] == 0.0\n",
    "neutro = samsung_data.loc[sum_neutro, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivo_text = ''\n",
    "for t in positivo['Treinamento']:\n",
    "    t = str(t)\n",
    "    positivo_text += t\n",
    "    \n",
    "samsung_pos = cleanup(positivo_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativo_text = ''\n",
    "for t in negativo['Treinamento']:\n",
    "    t = str(t)\n",
    "    negativo_text += t\n",
    "    \n",
    "samsung_neg = cleanup(negativo_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutro_text = ''\n",
    "for t in neutro['Treinamento']:\n",
    "    t = str(t)\n",
    "    neutro_text += t\n",
    "    \n",
    "samsung_neu = cleanup(neutro_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059343434343434344"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensinando o classificador para positivo\n",
    "serie_samsung_pos = pd.Series(samsung_pos.split())\n",
    "tabela_samsung_pos = serie_samsung_pos.value_counts()\n",
    "tabela_samsung_pos_relativa = serie_samsung_pos.value_counts(True)\n",
    "tabela_samsung_pos_relativa.sum()\n",
    "tabela_samsung_pos_relativa[\"samsung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047619047619047616"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensinando o classificador para negativo\n",
    "serie_samsung_neg = pd.Series(samsung_neg.split())\n",
    "tabela_samsung_neg = serie_samsung_neg.value_counts()\n",
    "tabela_samsung_neg_relativa = serie_samsung_neg.value_counts(True)\n",
    "tabela_samsung_neg_relativa.sum()\n",
    "tabela_samsung_neg_relativa[\"samsung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044142614601018676"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensinando o classificador para neutro\n",
    "serie_samsung_neu = pd.Series(samsung_neu.split())\n",
    "tabela_samsung_neu = serie_samsung_neu.value_counts()\n",
    "tabela_samsung_neu_relativa = serie_samsung_neu.value_counts(True)\n",
    "tabela_samsung_neu_relativa.sum()\n",
    "tabela_samsung_neu_relativa[\"samsung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilidade de conter samsung\n",
    "samsung = samsung_pos + samsung_neg + samsung_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047082348663879295"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construindo uma tabela samsung\n",
    "serie_samsung = pd.Series(samsung.split())\n",
    "tabela_samsung_relativa = serie_samsung.value_counts(True)\n",
    "tabela_samsung_relativa[\"samsung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interseçao de condições\n",
    "set_posi = set(tabela_samsung_pos_relativa.index)\n",
    "set_nega = set(tabela_samsung_neg_relativa.index)\n",
    "set_neut = set(tabela_samsung_neu_relativa.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando para um tweet\n",
    "\n",
    "frase = 'samsung me mandou um convite bacana para a pré venda do galaxy s20, aceitei...mas e aí cadê o dinheiro kkkkk sem falar do absurdo de caro que deve ser aqui no brasil'\n",
    "frase = cleanup(frase.lower())\n",
    "\n",
    "tabela_frase = pd.Series(frase.split())\n",
    "tabela_frase_a = tabela_frase.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samsung' 'me' 'mandou' 'um' 'convite' 'bacana' 'para' 'a' 'pré' 'venda'\n",
      " 'do' 'galaxy' 's20' 'aceitei' 'mas' 'e' 'aí' 'cadê' 'o' 'dinheiro'\n",
      " 'kkkkk' 'sem' 'falar' 'do' 'absurdo' 'de' 'caro' 'que' 'deve' 'ser'\n",
      " 'aqui' 'no' 'brasil']\n",
      "1.2916203455484921e-42\n",
      "1.4305544817694005e-83\n",
      "9.219763761821485e-66\n",
      "1.859595189373579e-43\n",
      "3.0582295411030993e-84\n",
      "5.92304038070844e-66\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades\n",
    "#pneg = tabela_samsung_relativa[serie_samsung_neg]\n",
    "#probneg = len(tabela_samsung)/len(serie_samsung_neg)\n",
    "\n",
    "tabela_samsung_absolut = serie_samsung.value_counts()\n",
    "tabela_samsung_absolut.sum()\n",
    "\n",
    "ppos = tabela_samsung_pos.sum()/tabela_samsung_absolut.sum()\n",
    "pneg = tabela_samsung_neg.sum()/tabela_samsung_absolut.sum()\n",
    "pneu = tabela_samsung_neu.sum()/tabela_samsung_absolut.sum()\n",
    "\n",
    "\n",
    "print(tabela_frase.values)\n",
    "\n",
    "pposPO=tabela_samsung_pos_relativa[tabela_frase.values]\n",
    "print(pposPO.prod())\n",
    "\n",
    "pposNG=tabela_samsung_neg_relativa[tabela_frase.values]\n",
    "print(pposNG.prod())\n",
    "\n",
    "pposNT=tabela_samsung_neu_relativa[tabela_frase.values]\n",
    "print(pposNT.prod())\n",
    "\n",
    "\n",
    "pposf =pposPO.prod()*ppos\n",
    "print(pposf)\n",
    "pnegf =pposNG.prod()*pneg\n",
    "print(pnegf)\n",
    "pneuf =pposNT.prod()*pneu\n",
    "print(pneuf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo a base teste\n",
    "base_teste = pd.ExcelFile('samsung1.xlsx')\n",
    "df1 = pd.read_excel(base_teste,'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.307703531150129e-26 4.610259100337782e-28 1.687693559375596e-29\n",
      "                                                 Teste  relevancia  classif\n",
      "0    tânia rocha um pouquinho de tudo - free fire n...           0      2.0\n",
      "1    cupom notebook e computadores -informática ace...           0      2.0\n",
      "2    @samsungbrasil verdade 🥺😥, já pedi um galaxy w...           1      2.0\n",
      "3    rt @purplesidestore: 💘promoção - cases bts (ip...           0      1.0\n",
      "4    @samsungbrasil eh sério samsung tô sem tv há 3...           0      2.0\n",
      "5    @phantomrenegado depois que parar de funcionar...           2      1.0\n",
      "6    @asusbr bd! comprei um aparelho dia 03/03, hj ...           2      1.0\n",
      "7    a samsung perguntando se eu quero saber tudo s...           0      1.0\n",
      "8    @andreiamelody1 amg n beije os vendedores da s...           0      0.0\n",
      "9    @samsungbrasil @lucassi28687778 kkkk samsung t...           2      1.0\n",
      "10   a samsung tá de sacanagem que vai lançar o gal...           0      1.0\n",
      "11   rapaziada\\n\\ntô vendendo um monitor de 21,5' p...           0      2.0\n",
      "12   @wagner_porto @xiaomibrasil meu tá morto desde...           1      2.0\n",
      "13   nosso cso, tomás trojan, também é um dos indic...           0      1.0\n",
      "14   @brunosader bruno, que tal participar da minha...           0      2.0\n",
      "15     samsung até o meu sono ela atrapalha me ligando           2      1.0\n",
      "16          @hobipied samsung. eles são patrocinadora.           0      0.0\n",
      "17   rt @trem_bebele: @vulgoloma eu nem ia posta ,t...           0      1.0\n",
      "18   samsung pay e google pay agora aceitam função ...           1      1.0\n",
      "19   mds sabe so queria meu cll de volta eu desapre...           0      2.0\n",
      "20   fabricantes de smartphones deveriam realocar o...           2      2.0\n",
      "21   alguém me traz um ciga e um carregador de sams...           0      1.0\n",
      "22   comprei um celular novinho da @samsung e ja es...           2      0.0\n",
      "23   eu c o samsung carregava o tele tipo d 2 em 2 ...           1      2.0\n",
      "24   @faabisf samsung, pq motorola depois de uns 6 ...           1      2.0\n",
      "25   samsung me explica pra mim, pq eu dei 4 mil re...           0      1.0\n",
      "26   rt @gustavo65251461: câmera de iphone // câmer...           0      1.0\n",
      "27   indo pra mais um treinamento! \\nque eu volte c...           0      1.0\n",
      "28   ontem eu thalyta e sthe no shopping kkkk tiran...           0      2.0\n",
      "29   @googlenest smartview da samsung, que transmit...           2      1.0\n",
      "..                                                 ...         ...      ...\n",
      "210  rt @bts_br: 🎥 j-hope para a campanha do @bts_t...           0      1.0\n",
      "211  certeza q o yoongs tiro essa foto ae com um sa...           0      2.0\n",
      "212  @leticiaar_m kkkkkkk nao vou nem defender a sa...           1      1.0\n",
      "213  rt @surtadazex: o meu samsung é igual mas por ...           0      1.0\n",
      "214  @bchartsnet vai flopar muito bc\\ntaylor: 6 #1 ...           0      2.0\n",
      "215  a huawei sem um pingo de vergonha na cara e co...           0      0.0\n",
      "216  @choegf @bts_twt a foto de samsung vei morro k...           0      0.0\n",
      "217  já baixei tanto jogo que na hora que eu ligo m...           0      1.0\n",
      "218  rt @canaltech: samsung anuncia primeiro lote d...           0      1.0\n",
      "219  rt @bts_br: 🎥 suga para a campanha do @bts_twt...           0      1.0\n",
      "220  🎥 j-hope para a campanha do @bts_twt com a sam...           0      1.0\n",
      "221  rt @fbrazilianarmy: 🎥| bts x samsung \\n\\n“#v n...           0      1.0\n",
      "222  rt @oficinadanet: samsung galaxy note 10+: vej...           0      2.0\n",
      "223  rt @bts_br: 🎥 rm para a campanha do @bts_twt c...           0      1.0\n",
      "224  🎥 jimin para a campanha do @bts_twt com a sams...           0      1.0\n",
      "225  rt @yosoycaio: um iphone faz a mesma ligação q...           0      2.0\n",
      "226  🎥| bts x samsung \\n\\n“#jungkook nós mostra com...           0      1.0\n",
      "227  ele some e quando aparece é cm uma foto tirada...           0      2.0\n",
      "228  rt @passionjeon: se é para ficar perto do que ...           0      1.0\n",
      "229  🎥| bts x samsung \\n\\n“#rm nós mostra como pode...           0      1.0\n",
      "230  né por nada não mas não sei como o povo defend...           0      1.0\n",
      "231  até agr sem acreditar que acharam o samsung po...           0      2.0\n",
      "232  rt @tourprojetosbts: [trad]\\n\"experimente autê...           0      2.0\n",
      "233  a samsung não tá errando 💜 @bts_twt https://t....           0      2.0\n",
      "234  samsung lança novo celular e agora toda hora a...           1      1.0\n",
      "235                @augustobt use o samsung branquinho           0      2.0\n",
      "236  rt @chuufuku: o iphone era a boca de fogão a g...           0      1.0\n",
      "237  lançamento do huawei p40 rolando na china. por...           2      2.0\n",
      "238  rt @bts_br: 🎥 v para a campanha do @bts_twt co...           0      1.0\n",
      "239  samsung minha filha vc atualiza a porra do cel...           2      1.0\n",
      "\n",
      "[240 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Percorrendo linha a linha e calculando probabilidades\n",
    "i=0\n",
    "for e in df1.Teste: \n",
    "    e = cleanup(e.lower())\n",
    "    x = re.sub(\"@[A-Za-z0-9]+\",\"\",e)\n",
    "    tweets = pd.Series(x.split())\n",
    "    \n",
    "    posit = 1\n",
    "    for p in tweets:\n",
    "        posit *= tabela_samsung_pos_relativa.get(p, 1)\n",
    "\n",
    "    negat = 1    \n",
    "    for p in tweets:\n",
    "        negat *= tabela_samsung_neg_relativa.get(p, 1)\n",
    "    \n",
    "    neutr = 1\n",
    "    for p in tweets:\n",
    "        neutr *= tabela_samsung_neu_relativa.get(p, 1)\n",
    "  \n",
    "    \n",
    "    posit = ppos*posit\n",
    "    negat = pneg*negat\n",
    "    neutr = pneu*neutr\n",
    "    \n",
    "    if posit > negat and posit > neutr:\n",
    "        classif = 1\n",
    "    elif negat > posit and negat > neutr:\n",
    "        classif = 2\n",
    "    elif neutr > posit and neutr > negat:\n",
    "        classif = 0\n",
    "        \n",
    "  \n",
    "    df1.loc[i, \"classif\"] = classif\n",
    "    i+=1\n",
    "    \n",
    "print(posit, negat,neutr)\n",
    "\n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classif</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classif     0.0  1.0  2.0\n",
       "relevancia               \n",
       "0             7  106   75\n",
       "1             2   11   13\n",
       "2             4   18    4"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparação entre Classificação Manual e o uso do classificador\n",
    "comparacao = (pd.crosstab(df1['relevancia'], df1['classif']))\n",
    "comparacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09166666666666666"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cálculo da porcentagem de acerto do Classificador\n",
    "j = 0\n",
    "total = 0\n",
    "while j < 240:\n",
    "    if df1.relevancia[j] == df1.classif[j]:\n",
    "        total += 1\n",
    "        \n",
    "    j+=1 \n",
    "total\n",
    "\n",
    "porc_acerto = total/len(df1)\n",
    "porc_acerto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos encontrar nesse trabalho a opinião publica sobre a marca de celulares Samsung, para isso pegamos uma serie de tweets relacionados a marca.\n",
    "Com a conclusão desse projeto, temos como resultado uma porcentagem bem abaixo do que era esperando. Com uma porcentagem de acerto por volta de 10% vimos que a grande maioria dos erros está nos tweets que nos colocamos o grau de relevância como “Neutro”.\n",
    "    Como uma justificativa disso, podemos observar que o classificador possui uma margem de erro muito grande quando comparado a novos métodos voltados a ciência dos dados.\n",
    "    De modo a minimizar esse erro uma alternativa serie utilizar uma base maior de tweets para treinar nosso classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Outras aplicações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras aplicações do  método de classificação de Naive Bayes podem ser encontradas por exemplo na análise de dados de exames laboratoriais, e também em caixa de entrada de emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
